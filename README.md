### **AI-Powered Medical Assistant with User-Specific Persistent Conversations**

<p align="center">
  <img src="https://img.shields.io/badge/FastAPI-Backend-green?style=for-the-badge">
  <img src="https://img.shields.io/badge/React-Frontend-blue?style=for-the-badge">
  <img src="https://img.shields.io/badge/Supabase-Authentication-3ECF8E?style=for-the-badge">
  <img src="https://img.shields.io/badge/LangChain-Orchestration-purple?style=for-the-badge">
  <img src="https://img.shields.io/badge/LangGraph-Persistent%20Memory-orange?style=for-the-badge">
  <img src="https://img.shields.io/badge/Docker-Deployment-cyan?style=for-the-badge">
</p>

---

## ğŸš€ Live Applications

### ğŸŒ Frontend (React)

ğŸ‘‰ [https://fullstack-medical-application-1.onrender.com/]

### âš™ï¸ Backend (FastAPI APIs)

ğŸ‘‰ [https://fullstack-medical-application-apis.onrender.com/]

### ğŸ“¦ GitHub Repository

ğŸ‘‰ [https://github.com/Warishayat/Fullstack-Medical-Application]

---

## ğŸ“Œ Project Overview

**Fullstack Medical AI Application** is a **production-grade SaaS AI medical assistant** that enables secure authentication, intelligent medical conversations, and **user-specific persistent chat memory**.

The system uses:

* **Supabase** for authentication & user management
* **LangChain** for LLM workflow orchestration
* **LangGraph** for stateful, persistent, per-user conversations

Each user continues their **own chat history** across sessions, securely isolated using their **Supabase user ID**.

---

## âœ¨ Key Features

### ğŸ” Supabase Authentication

* Secure signup & login
* JWT-based user sessions
* Supabase User ID used across backend
* Backend validates authenticated users only

---

### ğŸ§  AI Medical Assistant

* Symptom-based medical conversations
* Context-aware reasoning
* LLM-powered responses using Groq

---

### ğŸ”„ LangChain + LangGraph Orchestration (Core Feature)

#### ğŸ§© LangChain

* Prompt templates
* Tool chaining
* LLM integration
* Vector search via Pinecone

#### ğŸ•¸ LangGraph (Persistence Layer)

* **User-specific conversation graphs**
* Chat state bound to **Supabase user ID**
* Persistent memory across requests
* No conversation leakage between users

âœ… Each user has an **independent conversation graph**
âœ… Users resume chats after logout/login
âœ… Scalable orchestration architecture

---

## ğŸ§  How User-Specific Persistence Works

```text
User logs in (Supabase)
        â†“
Supabase returns authenticated user ID
        â†“
Backend extracts user ID from token
        â†“
LangGraph initialized with user-specific config
        â†“
Conversation state stored & retrieved per user
```

âœ” Fully isolated user sessions
âœ” Persistent AI memory
âœ” Production-ready design

---

## ğŸ—‚ Vector Memory (Pinecone)

* Medical conversation embeddings
* Semantic retrieval
* Long-term contextual memory
* Optimized for fast search

---

## ğŸ—ï¸ Tech Stack

### ğŸ”¹ Frontend

* React.js
* Axios
* Supabase Client SDK
* Hosted on Render

### ğŸ”¹ Backend

* FastAPI
* Supabase Auth (JWT verification)
* LangChain
* **LangGraph (Stateful Orchestration)**
* Pinecone Vector DB
* Groq LLM
* Docker

---

## ğŸ“‚ Project Structure

```
Fullstack-Medical-Application/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ Router/
â”‚   â”‚   â”œâ”€â”€ auth.py        # Supabase auth handling
â”‚   â”‚   â”œâ”€â”€ chat.py        # LangGraph orchestration
â”‚   â”‚   â””â”€â”€ message.py
â”‚   â”œâ”€â”€ Helper/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ pages/
â”‚   â””â”€â”€ supabaseClient.js
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ Backend Setup (Local)

```bash
git clone https://github.com/Warishayat/Fullstack-Medical-Application
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```

---

## ğŸ³ Backend Docker Setup

```bash
docker build -t medical-ai-backend .
docker run -p 8000:8000 -e PORT=8000 medical-ai-backend
```

---

## ğŸ”‘ Environment Variables

```env
SUPABASE_URL=your_url
SUPABASE_ANON_KEY=your_key
GROQ_API_KEY=your_key
GOOGLE_API_KEY=your_key
HUGGINGFACEHUB_ACCESS_TOKEN=your_key
PINECONE_API_KEY=your_key
```

(Set in **Render â†’ Environment Variables**)

---

## ğŸ”— API Health Check

```http
GET /
```

```json
{
  "status": 200,
  "message": "All routes are working fine"
}
```

---

## ğŸŒ Deployment Architecture

* Frontend â†’ Render (Static Web App)
* Backend â†’ Render (Docker Web Service)
* Authentication â†’ Supabase
* Vector DB â†’ Pinecone
* Orchestration â†’ LangChain + LangGraph
* LLM â†’ Groq

---

## ğŸ“ˆ Future Enhancements

* ğŸ§¾ Medical document upload & analysis
* ğŸ—£ Voice-based medical assistant
* ğŸ“Š User medical history dashboard
* ğŸ¥ Doctor recommendation system
* ğŸ§  Multi-agent LangGraph workflows

---

## ğŸ‘¨â€ğŸ’» Author

**Waris Hayat**
AI / ML Engineer

ğŸ”— GitHub: [https://github.com/Warishayat]

---

## â­ Support

If you like this project:

â­ Star the repo
ğŸ´ Fork it
ğŸ› Open issues
ğŸ’¡ Suggest features

---

add kar sakta hoon â€” just bolo ğŸ‘
